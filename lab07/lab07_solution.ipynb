{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "lab",
      "language": "python",
      "name": "lab"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVEmPHTK-7Kd"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "The goal of this tutorial is to implement a Variational Autoencoder (VAE) for Topic Models. The aim is to give you sense of: \n",
        "\n",
        "\n",
        "*   How topic models can be implemented under Variational Autoencoder (VAE)\n",
        "*   How the \"*reparametrization trick*\" enables backpropogation through latent variables\n",
        "\n",
        "\n",
        "Frist, we need to import neccesary packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eGKih-y-7Ki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd2627a8-81a7-4679-d654-02569e7bfe00"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import os\n",
        "import string\n",
        "import numpy as np\n",
        "import random\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import OrderedDict\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApPPC4zTSmkC",
        "outputId": "74ff080f-e1c5-4602-91be-01caf44567fb"
      },
      "source": [
        "###############\n",
        "# Torch setup #\n",
        "###############\n",
        "print('Torch version: {}, CUDA: {}'.format(torch.__version__, torch.version.cuda))\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "  print('WARNING: You may want to change the runtime to GPU for faster training!')\n",
        "  DEVICE = 'cpu'\n",
        "else:\n",
        "  DEVICE = 'cuda:0'\n",
        "\n",
        "#########################\n",
        "# Some helper functions #\n",
        "#########################\n",
        "def fix_seed(seed=None):\n",
        "  \"\"\"Sets the seeds of random number generators.\"\"\"\n",
        "  if seed is None:\n",
        "    # Take a random seed\n",
        "    seed = time.time()\n",
        "  seed = int(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  return seed\n",
        "\n",
        "fix_seed(1234)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch version: 1.7.0+cu101, CUDA: 10.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--RQRbdR-7Ki"
      },
      "source": [
        "## Data Preprocessing\n",
        "### Download dataset\n",
        "\n",
        "We experiment on a standard news corpora: the ***20NewsGroups*** and download it using scikit-learn. This dataset consists of 20k news articles classified into 20 topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQmS_Zqu-7Kj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c54b1ec-4164-4410-ae2b-2328ba162dd4"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "train_news_group = fetch_20newsgroups(subset='train')\n",
        "test_news_group = fetch_20newsgroups(subset='test')\n",
        "\n",
        "train_data = train_news_group['data']\n",
        "test_data = test_news_group['data']\n",
        "\n",
        "print(\"Size of training data:\", len(train_data))\n",
        "print(\"Size of test data:\", len(test_data))\n",
        "print(\"All topics:\", train_news_group.target_names)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training data: 11314\n",
            "Size of test data: 7532\n",
            "All topics: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEol3Jgp-7Kj"
      },
      "source": [
        "### Preprocess Dataset\n",
        "\n",
        "In this section, we define the functions to do conventional preprocessing and build the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1XdgwSg-7Kk"
      },
      "source": [
        "def preprocess(samples):\n",
        "    output = []\n",
        "    for item in samples:\n",
        "        words = item.replace('\\n', '').strip().lower().split(' ')\n",
        "        punctuations = (string.punctuation).replace(\"'\", \"\")\n",
        "        trans_table = str.maketrans('', '', punctuations)\n",
        "        stripped_words = [word.translate(trans_table) for word in words]\n",
        "        words = [str for str in stripped_words if str]\n",
        "        words = [word for word in words if not word.isdigit()]\n",
        "        words = [str for str in words if str]\n",
        "        output.append(words)\n",
        "    return output\n",
        "\n",
        "train_prep = preprocess(train_data)\n",
        "test_prep = preprocess(test_data)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fskcldry-7Kk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87578a83-2875-4edc-f086-fe188217f4ae"
      },
      "source": [
        "def get_vocab(data):\n",
        "    vocab = {}\n",
        "\n",
        "    stops = set(stopwords.words('english'))\n",
        "    ### -------------- TODO --------------- ###\n",
        "    # remove stop words and count frequency of words\n",
        "    for sent in data:\n",
        "        for word in sent:\n",
        "            if word in stops:\n",
        "                continue\n",
        "            if word in vocab:\n",
        "                vocab[word] += 1\n",
        "            else:\n",
        "                vocab[word] = 1\n",
        "    return vocab\n",
        "\n",
        "\n",
        "vocab_total = get_vocab(train_prep + test_prep)\n",
        "print(\"Total number of words in vocabulary:\", len(vocab_total))\n",
        "sorted(vocab_total.items(),key = lambda x:x[1],reverse = True)\n",
        "\n",
        "vocab = vocab_total\n",
        "\n",
        "'''\n",
        "Here we filter vocabulary to save some training time, otherwise our model input dimension would be huge (V=350k+).\n",
        "You can uncomment the line to include more words (around 52k words in vocabulary), which would help classifing the topics (Q4).\n",
        "'''\n",
        "vocab = {k:v for k,v in list(vocab_total.items())[:5000]}\n",
        "# vocab = {k:v for k,v in vocab_total.items() if v > 3}\n",
        "vocab_size = len(vocab)\n",
        "print(\"Vocabulary size after filtering:\", vocab_size)\n",
        "\n",
        "word2idx = {k:n for n,(k,v) in enumerate(vocab.items())}"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of words in vocabulary: 356832\n",
            "Vocabulary size after filtering: 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4WHKBGT-7Kk"
      },
      "source": [
        "train_doc = [[word for word in doc if word in vocab] for doc in train_prep]\n",
        "train_doc = [doc for doc in train_doc if len(doc) > 5]\n",
        "\n",
        "test_doc = [[word for word in doc if word in vocab] for doc in test_prep]\n",
        "test_doc = [doc for doc in test_doc if len(doc) > 5]"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMQRBCmA-7Kk"
      },
      "source": [
        "### Process Bag-of-words Inputs\n",
        "\n",
        "Next we define multiple helper functions to create input batches. Our inputs are represented in bag-of-word (bow) where each article/document is represented with a vector of **V** elements. We will also do the batching in this section, so the inputs to the models would be in the dimension of *(batch_size, vocab_size)*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZhYi_u_-7Kl"
      },
      "source": [
        "from collections import Counter\n",
        "def data_set(data_url):\n",
        "    \"\"\"process data input.\"\"\"\n",
        "    data = []\n",
        "    word_count = []\n",
        "    for words in data_url:\n",
        "        word2freq = dict(Counter(words))\n",
        "        doc = {}\n",
        "        count = 0\n",
        "\n",
        "        for word,freq in word2freq.items():\n",
        "            doc[int(word2idx[word])] = freq\n",
        "            count += freq\n",
        "\n",
        "        if count > 0:\n",
        "            data.append(doc)\n",
        "            word_count.append(count)\n",
        "\n",
        "    return data, word_count"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUw2w3jn-7Kl"
      },
      "source": [
        "def create_batches(data_size, batch_size, shuffle=True):\n",
        "    \"\"\"create a batch of indices.\"\"\"\n",
        "    batches = []\n",
        "    ids = list(range(data_size))\n",
        "    if shuffle:\n",
        "        random.shuffle(ids)\n",
        "    for i in range(data_size // batch_size):\n",
        "        start = i * batch_size\n",
        "        end = (i + 1) * batch_size\n",
        "        batches.append(ids[start:end])\n",
        "    # the batch of which the length is less than batch_size\n",
        "    rest = data_size % batch_size\n",
        "    if rest > 0:\n",
        "        batches.append(ids[-rest:] + [-1] * (batch_size - rest))  # -1 as padding\n",
        "    return batches"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU-GfOj4-7Kl"
      },
      "source": [
        "def fetch_data(data, count, idx_batch, vocab_size):\n",
        "    \"\"\"fetch input data by batch.\"\"\"\n",
        "    batch_size = len(idx_batch)\n",
        "    data_batch = np.zeros((batch_size, vocab_size))\n",
        "    count_batch = []\n",
        "    mask = np.zeros(batch_size)\n",
        "    indices = []\n",
        "    values = []\n",
        "    for i, doc_id in enumerate(idx_batch):\n",
        "        if doc_id != -1:\n",
        "            for word_id, freq in data[doc_id].items():\n",
        "                data_batch[i, word_id] = freq\n",
        "            count_batch.append(count[doc_id])\n",
        "            mask[i]=1.0\n",
        "        else:\n",
        "            count_batch.append(0)\n",
        "    return data_batch, count_batch, mask"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqyxSRTY-7Kl"
      },
      "source": [
        "### Question 1: Finish the neural structures of the VAE encoder and decoder, and the reparamerisation trick."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COC0bLTL-7Km"
      },
      "source": [
        "class TopicModel(nn.Module):\n",
        "    def __init__(self, \n",
        "                 vocab_size,\n",
        "                 input_size,\n",
        "                 n_hidden,\n",
        "                 n_topic, \n",
        "                 batch_size):\n",
        "        super(TopicModel, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_topic = n_topic\n",
        "        self.batch_size = batch_size\n",
        " \n",
        "        ### -------------- TODO --------------- ###\n",
        "        self.mu_layer = nn.Linear(n_hidden, n_topic)\n",
        "        self.logsigm_layer = nn.Linear(n_hidden, n_topic)\n",
        "\n",
        "        ### -------------- TODO --------------- ###\n",
        "        self.encoder = nn.Sequential(nn.Linear(input_size, n_hidden),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Linear(n_hidden, n_hidden),\n",
        "                                     nn.ReLU())\n",
        "        \n",
        "        ### -------------- TODO --------------- ###\n",
        "        self.decoder =  nn.Sequential(nn.Linear(n_topic, vocab_size),\n",
        "                                      nn.LogSoftmax(dim=-1))\n",
        "\n",
        "\n",
        "    def zero_bias(self,):\n",
        "        self.mu_layer.bias.data.fill_(0.0)\n",
        "        self.logsigm_layer.bias.data.fill_(0.0)\n",
        "        \n",
        "    def forward(self, input):\n",
        "\n",
        "        # encoder forward\n",
        "        doc_vec = self.encoder(input)\n",
        "        mu = self.mu_layer(doc_vec)\n",
        "        logsigm = self.logsigm_layer(doc_vec)\n",
        "        \n",
        "        # reparameterisation\n",
        "        ### -------------- TODO --------------- ###\n",
        "        eps = torch.normal(0,1, size=(self.batch_size, self.n_topic), device=DEVICE)\n",
        "        z = mu + logsigm.exp()*eps\n",
        "\n",
        "        # decoder forward\n",
        "        logits = self.decoder(z)\n",
        "        \n",
        "        # recons\n",
        "        ### -------------- TODO --------------- ###\n",
        "        recons = -torch.sum(logits*input, dim=1)\n",
        "        \n",
        "        # kld\n",
        "        ### -------------- TODO --------------- ###\n",
        "        kld = -0.5 * torch.sum(1 - torch.square(mu) + 2*logsigm - torch.exp(2*logsigm), dim=1)\n",
        "        \n",
        "        loss = torch.mean(recons + kld)\n",
        "        recons = torch.mean(recons)\n",
        "        kld = torch.mean(kld)\n",
        "\n",
        "        # print(loss, recons, kld)\n",
        "        \n",
        "\n",
        "        return loss, recons, kld"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we2gyAVH-7Kn"
      },
      "source": [
        "### Question 2: Finish the Training File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0x-2Apf-7Km"
      },
      "source": [
        "def main_train():\n",
        "    num_epoch = 20\n",
        "    batch_size = 64\n",
        "    vocab_size = len(vocab)\n",
        "    n_hidden = 256\n",
        "    n_topic = 50\n",
        "    learning_rate = 0.0001\n",
        "    alternate_epochs = 5\n",
        "    \n",
        "    train_set, train_count = data_set(train_doc)\n",
        "    \n",
        "    ### -------------- TODO --------------- ###\n",
        "    model = TopicModel(vocab_size=vocab_size, \n",
        "                       input_size=vocab_size, \n",
        "                       n_hidden=n_hidden, \n",
        "                       n_topic=n_topic, \n",
        "                       batch_size=batch_size)\n",
        "    \n",
        "    model.zero_bias()\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    ### -------------- TODO --------------- ###\n",
        "    optimizer_enc = torch.optim.Adam([{'params':model.encoder.parameters()}, \n",
        "                                      {'params':model.mu_layer.parameters()},\n",
        "                                      {'params':model.logsigm_layer.parameters()}],\n",
        "                                     lr = learning_rate,\n",
        "                                     eps= 1e-8)\n",
        "    optimizer_dec = torch.optim.Adam([{'params':model.decoder.parameters()}], \n",
        "                                     lr = learning_rate,\n",
        "                                     eps= 1e-8)\n",
        "    \n",
        "    for epoch in range(num_epoch):\n",
        "        train_batches = create_batches(len(train_set), batch_size, shuffle=True)\n",
        "        model.train() \n",
        "        \n",
        "        ### -------------- TODO --------------- ###\n",
        "        # Question: why do we need two optimizers #\n",
        "        # Answer: To help escape local minimum, but it might not be necessary.\n",
        "        for switch in range(0, 2): \n",
        "            if switch == 0:\n",
        "                optimizer = optimizer_dec\n",
        "                print_mode = 'updating decoder'\n",
        "            else:\n",
        "                optimizer = optimizer_enc\n",
        "                print_mode = 'updating encoder'\n",
        "                \n",
        "            loss_epoch = 0.0\n",
        "            recons_epoch = 0.0\n",
        "            kld_epoch = 0.0\n",
        "            count = 0\n",
        "    \n",
        "            for i in range(alternate_epochs):\n",
        "                                 \n",
        "                for idx_batch in train_batches:\n",
        "                    data_batch, count_batch, mask = fetch_data(train_set, train_count, idx_batch, vocab_size)\n",
        "                    input = torch.from_numpy(data_batch).float().to(DEVICE)\n",
        "                    loss, recons, kld = model(input)\n",
        "                    \n",
        "                    # optimize\n",
        "                    optimizer.zero_grad()      \n",
        "                    loss.backward()        \n",
        "                    optimizer.step()        \n",
        "                    loss_epoch += loss\n",
        "                    recons_epoch += recons\n",
        "                    kld_epoch += kld\n",
        "                    count += 1\n",
        "\n",
        "            print(f'Epoch {epoch}, loss={loss_epoch/count}, recons={recons_epoch/count}, kld={kld_epoch/count}')\n",
        "\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDZraKb1-7Kn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4c0a75-829d-479a-eaf7-d353f821e4a2"
      },
      "source": [
        "model = main_train()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss=596.6555786132812, recons=596.5907592773438, kld=0.06485079973936081\n",
            "Epoch 0, loss=582.9100952148438, recons=579.7217407226562, kld=3.187455892562866\n",
            "Epoch 1, loss=550.35205078125, recons=546.1802978515625, kld=4.171688556671143\n",
            "Epoch 1, loss=523.10986328125, recons=511.15966796875, kld=11.950454711914062\n",
            "Epoch 2, loss=515.8670043945312, recons=501.99493408203125, kld=13.872203826904297\n",
            "Epoch 2, loss=510.50341796875, recons=497.9371032714844, kld=12.566522598266602\n",
            "Epoch 3, loss=506.73638916015625, recons=492.8454284667969, kld=13.891047477722168\n",
            "Epoch 3, loss=503.03216552734375, recons=490.366455078125, kld=12.665414810180664\n",
            "Epoch 4, loss=499.25836181640625, recons=486.4047546386719, kld=12.853713035583496\n",
            "Epoch 4, loss=496.37567138671875, recons=483.6053466796875, kld=12.770222663879395\n",
            "Epoch 5, loss=493.532470703125, recons=480.9125671386719, kld=12.620038032531738\n",
            "Epoch 5, loss=491.2666320800781, recons=478.1276550292969, kld=13.13899040222168\n",
            "Epoch 6, loss=488.9847106933594, recons=475.3402099609375, kld=13.6447114944458\n",
            "Epoch 6, loss=487.0204772949219, recons=473.33624267578125, kld=13.68348503112793\n",
            "Epoch 7, loss=485.4287414550781, recons=471.2015380859375, kld=14.22722053527832\n",
            "Epoch 7, loss=483.9501953125, recons=469.5906677246094, kld=14.35941219329834\n",
            "Epoch 8, loss=482.4938049316406, recons=467.3606872558594, kld=15.133149147033691\n",
            "Epoch 8, loss=481.1770935058594, recons=466.1227722167969, kld=15.054523468017578\n",
            "Epoch 9, loss=479.7466125488281, recons=464.6759338378906, kld=15.07060718536377\n",
            "Epoch 9, loss=478.6155700683594, recons=463.145263671875, kld=15.470093727111816\n",
            "Epoch 10, loss=477.4605712890625, recons=461.7642517089844, kld=15.695751190185547\n",
            "Epoch 10, loss=476.5316467285156, recons=460.5525817871094, kld=15.979020118713379\n",
            "Epoch 11, loss=475.4903869628906, recons=459.37945556640625, kld=16.110761642456055\n",
            "Epoch 11, loss=474.4544372558594, recons=458.1086730957031, kld=16.345996856689453\n",
            "Epoch 12, loss=473.6183776855469, recons=456.6183776855469, kld=17.000080108642578\n",
            "Epoch 12, loss=472.74853515625, recons=455.81011962890625, kld=16.938549041748047\n",
            "Epoch 13, loss=472.0554504394531, recons=455.00933837890625, kld=17.04619026184082\n",
            "Epoch 13, loss=471.3420715332031, recons=453.9245910644531, kld=17.417484283447266\n",
            "Epoch 14, loss=470.66656494140625, recons=452.5328063964844, kld=18.133726119995117\n",
            "Epoch 14, loss=469.9061279296875, recons=451.8856506347656, kld=18.020824432373047\n",
            "Epoch 15, loss=469.2080078125, recons=451.3548583984375, kld=17.85353660583496\n",
            "Epoch 15, loss=468.5857849121094, recons=450.250732421875, kld=18.33527946472168\n",
            "Epoch 16, loss=467.8678894042969, recons=449.3752746582031, kld=18.49273109436035\n",
            "Epoch 16, loss=467.3861389160156, recons=448.6500549316406, kld=18.7362117767334\n",
            "Epoch 17, loss=466.93194580078125, recons=448.2524108886719, kld=18.67902374267578\n",
            "Epoch 17, loss=466.27685546875, recons=447.2178039550781, kld=19.05903434753418\n",
            "Epoch 18, loss=465.58856201171875, recons=446.5816955566406, kld=19.006309509277344\n",
            "Epoch 18, loss=465.1720275878906, recons=445.7235412597656, kld=19.44812774658203\n",
            "Epoch 19, loss=464.6462097167969, recons=444.65789794921875, kld=19.988338470458984\n",
            "Epoch 19, loss=464.27301025390625, recons=444.41937255859375, kld=19.85401153564453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dsk3rJC_NKX"
      },
      "source": [
        "# save model to use in Q4\n",
        "torch.save(model.state_dict(), \"vae.pt\")"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBJ4Mqyb-7Kn"
      },
      "source": [
        "### Question 3: Code qualitative analysis for topics (p(x|z))\n",
        "Now that we have the VAE trained with 50 candidate topics, we can explore how the VAE model cluster words with similar topics together.\n",
        "\n",
        "In the following section, you will also need to evaluate the perplexity of the VAE model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtFfNW5b-7Kn"
      },
      "source": [
        "#Add meta information (authors, time, geolocation etc.) to improve quality of the topics\n",
        "\n",
        "associations = {\n",
        "    'jesus': ['prophet', 'jesus', 'matthew', 'christ', 'worship', 'church'],\n",
        "    'comp ': ['floppy', 'windows', 'microsoft', 'monitor', 'workstation', 'macintosh', \n",
        "              'printer', 'programmer', 'colormap', 'scsi', 'jpeg', 'compression'],\n",
        "    'car  ': ['wheel', 'tire'],\n",
        "    'polit': ['amendment', 'libert', 'regulation', 'president'],\n",
        "    'crime': ['violent', 'homicide', 'rape'],\n",
        "    'midea': ['lebanese', 'israel', 'lebanon', 'palest'],\n",
        "    'sport': ['coach', 'hitter', 'pitch'],\n",
        "    'gears': ['helmet', 'bike'],\n",
        "    'nasa ': ['orbit', 'spacecraft'],\n",
        "}\n",
        "def identify_topic_in_line(line):\n",
        "    topics = []\n",
        "    for topic, keywords in associations.items():\n",
        "        for word in keywords:\n",
        "            if word in line:\n",
        "                topics.append(topic)\n",
        "                break\n",
        "    return topics\n",
        "\n",
        "def print_top_words(beta, feature_names, n_top_words=10):\n",
        "    print('---------------Printing the Topics------------------')\n",
        "    for i in range(len(beta)):\n",
        "        line = \" \".join([feature_names[j][0] for j in beta[i].argsort()[:-n_top_words - 1:-1]])\n",
        "        topics = identify_topic_in_line(line)\n",
        "        print('|'.join(topics))\n",
        "        print('     {}'.format(line))\n",
        "    print('---------------End of Topics------------------')\n",
        "\n",
        "\n",
        "def print_perp(model):\n",
        "    cost=[]\n",
        "    model.eval()\n",
        "    test_set, test_count = data_set(test_doc)\n",
        "    test_batches = create_batches(len(test_set), 64)\n",
        "    \n",
        "    ### -------------- TODO --------------- ###\n",
        "    loss_sum = 0\n",
        "    word_count = 0\n",
        "    for idx_batch in test_batches:\n",
        "        data_batch, count_batch, mask = fetch_data(test_set, test_count, idx_batch, vocab_size)\n",
        "        test_input = torch.from_numpy(data_batch).float().to(DEVICE)\n",
        "        loss, recons, kld = model(test_input)\n",
        "\n",
        "        loss_sum += (loss.item() * 64)\n",
        "        word_count += np.sum(count_batch)\n",
        "\n",
        "    ppl = np.exp(loss_sum / word_count)\n",
        "    print('The approximated perplexity is: ', ppl)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# perplexity on test data\n",
        "print_perp(model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72hnyu6EHMM2",
        "outputId": "65724555-c27b-4d44-bcf3-d12d8f1eb945"
      },
      "source": [
        "# model latent topics\n",
        "emb = model.decoder[0].weight.data.cpu().numpy().T\n",
        "print_top_words(emb, sorted(vocab.items(), key=lambda x:x[1]))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------Printing the Topics------------------\n",
            "\n",
            "     grubb loney gripe jupiter's celica grubbsubject smog hill ulysses marlborough\n",
            "\n",
            "     those'new adeos effi highprimers dangerous runsgameand pharisees used\t\t\t\t\t\t\t\t roundassuming autotheft\n",
            "\n",
            "     war ago regularly center box goes truth office ask buy\n",
            "\n",
            "     essence ab condition putting anywhere approximately ialines intend hill gravity\n",
            "\n",
            "     dlecointgarnetacnsfsuedu rosenblattsubject sys ludicrous suspended noobvious lloyd piaget requirements galaxies\to\n",
            "\n",
            "     lloyd csyphersuafhpuarkedu jupiter rodcfchpcom flynnuniversity piaget systems acceptance september celicagt\n",
            "\n",
            "     classic intend launched 32in used\t\t\t\t\t\t\t\t gravity approximately rumors travel griffin\n",
            "\n",
            "     rosenblattsubject brain andwingless it'shard titan's updating wrongness posting scaliness aroundan\n",
            "\n",
            "     narrowed claim11 topicsthe messagex jap tocomprehend 35andy dansjdcgssmotcom theseason isclean\n",
            "\n",
            "     theodore smith year's richardson escape convenient purchasing rod for\t handguns\n",
            "\n",
            "     pegasus worlddoes actual exploration pullout merged smith 3b2 autodoublerdiskdoubler donated\n",
            "\n",
            "     jupiter energy sooo codes fancy watching iiitos throttle moviesin furthermore\n",
            "\n",
            "     sabbath qualified andone environment pantheism tvorganization m32bkw txt ysebaert xmotif\n",
            "\n",
            "     x11r3 corporationjgreencsdharriscom\t\t\tcomputer jung owens ridiculously rednecks newsgroup yearbut bibleto tromsoe\n",
            "\n",
            "     limiter massacres completion flynnuniversity apr9083925199315639romulusrutgersedu restrictstronger runningthrowing manuver willissubject detroitorganization\n",
            "\n",
            "     centerline talon intelligence thunder'89 hey ready radiator innocent committee onto\n",
            "\n",
            "     thatmatter rebel establishes vin olcyzk immense painless granted thisnntppostinghost ratherpevasive\n",
            "\n",
            "     traditional solarstudies till immediate wonderful multiple contents replies thunderbird complaints\n",
            "\n",
            "     annullaw informix ordering number white\t tcpipaccess actual aren'tset wiener humanbuilt\n",
            "\n",
            "     twillisececnpurdueedu but\ti secondhand violationsin ended science\t iconcluded neville referred separates\n",
            "jesus\n",
            "     bloch\t jean answer otherwise machines overit inthe christiaan thankdirectly theway\n",
            "\n",
            "     preston smog ulysses login gripe lustig andone allthat sinks liftoff\n",
            "\n",
            "     carsonuwashingtonedua healthyou informix flare chhabrasubject nonexistant lines weakencryption condition blank\n",
            "\n",
            "     billmsicomorganization godon't departmentisn't priorities thewar furthermore trek pullout formation lindbergh\n",
            "\n",
            "     a137490lehtoricctutfi idaho run ruled jupiter 6is plesac ok sell thatdarryl\n",
            "\n",
            "     p9000 restrictions constant summaryorganization itis \t tilted writesexcerpts pl5lines ridiculously\n",
            "\n",
            "     batting modify mercury reportskeywords increasing iowa bunchof codes 14nntppostinghost v6\n",
            "\n",
            "     weakencryption subcompact 924i porschedealer fiddling atextual insurancecompanies majorchangesoption xterminalconfiguration infinity\n",
            "\n",
            "     hpoe rpwhitecsnpsnavymil unforgiven highprimers questionorganization yassin oktooif driving portion projectessentially\n",
            "\n",
            "     gavethe justtakes movieskeywords kfar expansionlustnntppostinghost jaraczsubject clearness checktoday release\t 14yo\n",
            "comp \n",
            "     enhanced kinda programmer theodore clh interpret impressive access october targets\n",
            "\n",
            "     lists att road remain tcorapicaarmymil along system captaincy audi wasstrictly\n",
            "\n",
            "     annullaw autodoublerdiskdoubler 800number sorts csyphersuafhpuarkedu spacenewprobeslastmodified respectiveteams worlddoes engineeringconvictions regularly\n",
            "\n",
            "     condition fromchicago first baby ruled writesfolksi sufficientlynicely stac's collecting additional\n",
            "\n",
            "     berthing likelyto runningthrowing highquote micrometeroid facility rpwhitesubject gamesis xrayisriceedu clear\n",
            "\n",
            "     earth\to stinsurance likemoog's quadrilateral turbo advantageam 'intifadah' porschedealer aruger publicat\n",
            "comp \n",
            "     glinossubject necessaryeasy mightbe advantage errors caucasian flybys writesfolksi seescsi1 kjenksgothamcityjscnasagov\n",
            "\n",
            "     regularly ab powerbook launched gravity campaign rider travel could glinossubject\n",
            "\n",
            "     cartridgedrives computracrichardsontxirwincmptrclonestarorg iiitos probleman accel regular havea intention good somewhere\n",
            "\n",
            "     pace sfu core requirements wife's got used\t\t\t\t\t\t\t\t kansas eventsoutput folks\n",
            "\n",
            "     here's western cartridgedrives board soi billmsicom watching they're trigger equipped\n",
            "comp \n",
            "     possibleken budienny monitor opposite hiring but\ti neutron\t front dopey vintage\n",
            "\n",
            "     20oo donated sooo haslacked brenda csyphersuafhpuarkedu quote game cold oilers\n",
            "\n",
            "     orservice immediatelydropped runsgameand dopey supportplease lie mexicoinsurance ouchit appeal thewar\n",
            "\n",
            "     engineers jeffrey steve and\t rumors foreign sue gretzky ago stan\n",
            "\n",
            "     allstate led supply togentile fulfill bad nhl mvp\t aspects lab\n",
            "\n",
            "     and\t\talways green\t\t\t\tharris noobvious men atnuclear etc possibleken authority whereboth killing\n",
            "\n",
            "     wayinitially knock million recguns greatest indifferent combinations 70s mad atmospheric\n",
            "\n",
            "     appeared ridiculously rider sony yearbut mpixel september motion ini'm maryland\n",
            "\n",
            "     supportplease plesac neededreplyto orservice manuver systems informationcaliforniamale overturned majority abraham\n",
            "---------------End of Topics------------------\n",
            "The approximated perplexity is:  1086.558542521707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iw_8gul-7Kn"
      },
      "source": [
        "### Question 4: Use Topics to do Classification\n",
        "In this section, you will use both the article and the labels to train a topic classifier. Firstly, you may train a vanilla classifier, and you are likely to get around 83% validation accuracy with a vocabulary of 50k (the accuracy might be lower with a small vocabulary). Then you can use the pre-trained VAE encoder as the classifier encoder and fine-tune it to see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xU4DjHwZa2W",
        "outputId": "b19009ca-d2f0-4ed0-ea30-c7dd279f69ee"
      },
      "source": [
        "'''\n",
        "Uncomment these lines to train the classifier on larger vocabulary\n",
        "NOTE: if you want to use the pre-trained VAE encoder, the vocab size for the classifier should be the same as the VAE model\n",
        "'''\n",
        "\n",
        "# vocab = {k:v for k,v in vocab_total.items() if v > 3}\n",
        "# vocab_size = len(vocab)\n",
        "# print(\"Vocabulary size after filtering:\", vocab_size)\n",
        "# word2idx = {k:n for n,(k,v) in enumerate(vocab.items())}"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size after filtering: 52199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPEoNEUAodhk"
      },
      "source": [
        "def fetch_labelled_data(data, labels, idx_batch, vocab_size):\n",
        "    \"\"\"fetch input data and labels by batch.\"\"\"\n",
        "    batch_size = len(idx_batch)\n",
        "    data_batch = np.zeros((batch_size, vocab_size))\n",
        "    label_batch = []\n",
        "\n",
        "    texts_batch = [data[i] for i in idx_batch]\n",
        "    label_batch = [labels[i] for i in idx_batch]\n",
        "\n",
        "    for i, text in enumerate(texts_batch):\n",
        "        for word in text:\n",
        "            if word in vocab:\n",
        "                data_batch[i, word2idx[word]] += 1\n",
        "\n",
        "    return data_batch, np.array(label_batch)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg3DQ0uB-7Ko"
      },
      "source": [
        "class VanillaClassifier(nn.Module):\n",
        "    def __init__(self, input_size, n_hidden, n_class, dp):\n",
        "        super().__init__()\n",
        "\n",
        "        ### --------------------- TODO ----------------------- ###\n",
        "        # construct a same encoder architecture as the VAE encoder \n",
        "        self.encoder = nn.Sequential(nn.Linear(input_size, n_hidden),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Linear(n_hidden, n_hidden),\n",
        "                                     nn.ReLU(),\n",
        "                                    )\n",
        "        self.dropout = nn.Dropout(dp)\n",
        "        self.output = nn.Linear(n_hidden, n_class, bias=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        doc_vec = self.dropout(self.encoder(input))\n",
        "        logits = self.output(doc_vec)\n",
        "        return logits\n",
        "\n",
        "class VAEClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vae, n_class, dp):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = vae.encoder\n",
        "        self.vae_output = vae.n_hidden\n",
        "        \n",
        "        self.dropout = nn.Dropout(dp)\n",
        "        self.output = nn.Linear(self.vae_output, n_class, bias=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        doc_vec = self.dropout(self.encoder(input))\n",
        "\n",
        "        logits = self.output(doc_vec)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouucz820EQwa"
      },
      "source": [
        "def evaluate(classifier, idx_batches, data, labels, vocab_size, criterion):\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        val_count = 0\n",
        "\n",
        "        for idx_batch in idx_batches:\n",
        "            ### --------------------- TODO ----------------------- ###\n",
        "            # compute validation loss and accuracy\n",
        "            data_batch, label_batch = fetch_labelled_data(data, labels, idx_batch, vocab_size)\n",
        "\n",
        "            input = torch.from_numpy(data_batch).float().to(DEVICE)\n",
        "            target = torch.from_numpy(label_batch).to(DEVICE)\n",
        "\n",
        "            pred = classifier(input)\n",
        "\n",
        "            _, predictions = torch.max(pred, dim=1)\n",
        "            loss = criterion(pred, target)\n",
        "\n",
        "            total_acc += torch.mean((predictions == target).float())\n",
        "            total_loss += loss.item()\n",
        "            val_count += 1\n",
        "\n",
        "    return total_loss/val_count, total_acc/val_count"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY39UKMPojYV"
      },
      "source": [
        "def cls_train(train_data, train_labels, valid_data, valid_labels, vocab_size):\n",
        "    num_epoch = 10\n",
        "    batch_size = 64\n",
        "    dropout = 0.1\n",
        "    n_hidden = 64\n",
        "    learning_rate = 0.0001\n",
        "    \n",
        "    # model.load_state_dict(torch.load(\"vae.pt\"))\n",
        "    # classifier = VAEClassifier(model, 20, dropout)\n",
        "    classifier = VanillaClassifier(vocab_size, n_hidden, 20, dropout)\n",
        "\n",
        "    classifier.to(DEVICE)\n",
        "\n",
        "    optimizer = torch.optim.Adam(classifier.parameters(),\n",
        "                                     lr = learning_rate)\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    for epoch in range(num_epoch):\n",
        "        train_batches = create_batches(len(train_prep), batch_size, shuffle=True)\n",
        "        valid_batches = create_batches(len(test_prep), batch_size, shuffle=False)\n",
        "        \n",
        "                \n",
        "        train_loss = 0.0\n",
        "        count = 0\n",
        "        acc = 0\n",
        "        classifier.train()              \n",
        "        for idx_batch in train_batches:\n",
        "            optimizer.zero_grad()\n",
        "            ### --------------------- TODO ----------------------- ###\n",
        "            # finish training loop\n",
        "            data_batch, label_batch = fetch_labelled_data(train_data, train_labels, idx_batch, vocab_size)\n",
        "            input = torch.from_numpy(data_batch).float().to(DEVICE)\n",
        "            target = torch.from_numpy(label_batch).to(DEVICE)\n",
        "\n",
        "            pred = classifier(input)\n",
        "\n",
        "            _, predictions = torch.max(pred, dim=1)\n",
        "            acc += torch.mean((predictions == target).float())\n",
        "\n",
        "            loss = criterion(pred, target)\n",
        "            \n",
        "            # optimize \n",
        "            loss.backward()        \n",
        "            optimizer.step()        \n",
        "            train_loss += loss\n",
        "            count += 1\n",
        "        \n",
        "        # validation\n",
        "        classifier.eval()\n",
        "        valid_loss, valid_acc = evaluate(classifier, valid_batches, valid_data, test_labels, vocab_size, criterion)\n",
        "        print(f'Epoch {epoch},\\ttrain_loss={train_loss/count:.3f},\\ttrain_acc={acc/count:.3f},\\tvalid_loss={valid_loss:.3f},\\tvalid_acc={valid_acc:.3f}')"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6CR2PohDC2B",
        "outputId": "18fbdea8-cd27-4481-ca4f-9b71b2de7c4e"
      },
      "source": [
        "cls_train(train_prep, train_labels, test_prep, test_labels, vocab_size)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0,\ttrain_loss=2.964,\ttrain_acc=0.139,\tvalid_loss=2.917,\tvalid_acc=0.258\n",
            "Epoch 1,\ttrain_loss=2.785,\ttrain_acc=0.393,\tvalid_loss=2.699,\tvalid_acc=0.425\n",
            "Epoch 2,\ttrain_loss=2.484,\ttrain_acc=0.513,\tvalid_loss=2.412,\tvalid_acc=0.514\n",
            "Epoch 3,\ttrain_loss=2.152,\ttrain_acc=0.594,\tvalid_loss=2.135,\tvalid_acc=0.579\n",
            "Epoch 4,\ttrain_loss=1.856,\ttrain_acc=0.653,\tvalid_loss=1.907,\tvalid_acc=0.613\n",
            "Epoch 5,\ttrain_loss=1.616,\ttrain_acc=0.688,\tvalid_loss=1.741,\tvalid_acc=0.628\n",
            "Epoch 6,\ttrain_loss=1.438,\ttrain_acc=0.714,\tvalid_loss=1.618,\tvalid_acc=0.639\n",
            "Epoch 7,\ttrain_loss=1.296,\ttrain_acc=0.733,\tvalid_loss=1.526,\tvalid_acc=0.644\n",
            "Epoch 8,\ttrain_loss=1.173,\ttrain_acc=0.755,\tvalid_loss=1.453,\tvalid_acc=0.645\n",
            "Epoch 9,\ttrain_loss=1.077,\ttrain_acc=0.771,\tvalid_loss=1.399,\tvalid_acc=0.652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft3SMu7vXsjI"
      },
      "source": [
        "Since the training of VAE takes a long time, the vocabulary was truncated into 5000 words. Therefore, the benefit from VAE pre-training might not seem very obvious. You may try and train a new VAE with a larger vocabulary (e.g. 50k and train for 20 epochs), it would help in classifing the topics.\n",
        "\n",
        "In addition, the validation accuracy might be low if your vocabulary size is only 5,000 (valid acc around 65%). The below code is just a baseline utilizing all the words, and it would achieve around 83% accuracy on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCVaP-MhjoXY",
        "outputId": "051ad19b-66e8-4744-959c-fd8f09a6aa9b"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "train_features = vectorizer.fit_transform(train_data)\n",
        "test_features = vectorizer.transform(test_data)\n",
        "\n",
        "train_labels = np.array(train_news_group['target'])\n",
        "test_labels = np.array(test_news_group['target'])\n",
        "\n",
        "vocab_size = len(vectorizer.vocabulary_)\n",
        "print(vocab_size)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "130107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBG5Xxuy1zmX"
      },
      "source": [
        "def fetch_labelled_data(features, labels, idx_batch, vocab_size=None):\n",
        "    idxs = np.array(idx_batch)\n",
        "\n",
        "    feature_batch = features[idxs, :].toarray()\n",
        "    label_batch = labels[idxs]\n",
        "    return feature_batch, label_batch"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJIIc5pPW_Qb",
        "outputId": "2feb467d-8798-4546-b887-12a7b9c881ab"
      },
      "source": [
        "cls_train(train_features, train_labels, test_features, test_labels, vocab_size)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0,\ttrain_loss=2.844,\ttrain_acc=0.261,\tvalid_loss=2.673,\tvalid_acc=0.510\n",
            "Epoch 1,\ttrain_loss=2.259,\ttrain_acc=0.746,\tvalid_loss=2.130,\tvalid_acc=0.734\n",
            "Epoch 2,\ttrain_loss=1.587,\ttrain_acc=0.880,\tvalid_loss=1.642,\tvalid_acc=0.793\n",
            "Epoch 3,\ttrain_loss=1.084,\ttrain_acc=0.916,\tvalid_loss=1.334,\tvalid_acc=0.807\n",
            "Epoch 4,\ttrain_loss=0.773,\ttrain_acc=0.938,\tvalid_loss=1.137,\tvalid_acc=0.821\n",
            "Epoch 5,\ttrain_loss=0.563,\ttrain_acc=0.961,\tvalid_loss=1.012,\tvalid_acc=0.822\n",
            "Epoch 6,\ttrain_loss=0.426,\ttrain_acc=0.970,\tvalid_loss=0.921,\tvalid_acc=0.827\n",
            "Epoch 7,\ttrain_loss=0.327,\ttrain_acc=0.976,\tvalid_loss=0.862,\tvalid_acc=0.828\n",
            "Epoch 8,\ttrain_loss=0.258,\ttrain_acc=0.983,\tvalid_loss=0.835,\tvalid_acc=0.828\n",
            "Epoch 9,\ttrain_loss=0.207,\ttrain_acc=0.986,\tvalid_loss=0.797,\tvalid_acc=0.828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKSA5sl6XFSh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}